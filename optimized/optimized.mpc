import time
import sys
import math
import warnings
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.utils.multiclass import type_of_target
from sklearn.base import BaseEstimator, ClassifierMixin

from Compiler import mpc_math, ml

# -------------------------------- METRICS --------------------------------

def calculate_metrics(y_test, y_pred, positive_label=0, plain_test = True):
    true_positive_arr = Array(len(y_test), sint)
    false_positive_arr = Array(len(y_test), sint)
    false_negative_arr = Array(len(y_test), sint)

    if (plain_test): # Test is a normal python public array. Transform to secret shared to compare
        y_testing = y_test
        y_test = Array(len(y_testing), sint)
        y_test.assign(y_testing)

    @for_range_opt(len(y_test))
    def f(i):
        y_t = y_test[i].reveal()
        y_p = y_pred[i].reveal()
        true_positive_arr[i] = ((y_p == positive_label) & (y_t == positive_label)).if_else(1,0)
        false_positive_arr[i] = ((y_p == positive_label) & (y_t != positive_label)).if_else(1,0)
        false_negative_arr[i] = ((y_p != positive_label) & (y_t == positive_label)).if_else(1,0)

    true_positive = sum(true_positive_arr)
    false_positive = sum(false_positive_arr)
    false_negative = sum(false_negative_arr)

    precision = (true_positive + false_positive != 0).if_else(true_positive / (true_positive + false_positive), 0)
    recall = (true_positive + false_negative != 0).if_else(true_positive / (true_positive + false_negative), 0)

    return precision, recall


# -------------------------------- UTILS --------------------------------

E = 2.71828

# Array operations

def sum_of_equal_scalar(arr, value):
    count = Array(len(arr)+1, sint)
    count[0] = sint(0)
    @for_range_opt(len(arr))
    def _(i):
        count[i+1] =  count[i] + (arr[i] == value)
    return count[len(arr)]

def cantor(x, y):
    return (x + y) * (x + y + 1) * cfix(0.5) + y

def find_nth_largest_value_from_array(arr, n):
    result = Array(len(arr)+1, sfix)
    result[0] = sfix(0.0)
    @for_range_opt(len(arr))
    def _(i):
        number_of_numbers_lower = Array(len(arr)+1, sint)
        number_of_numbers_lower[0] = sint(-1) # offset 1 since it is always going to be equal for j=i
        @for_range_opt(len(arr))
        def _(j):
            number_of_numbers_lower[j+1] = number_of_numbers_lower[j] + (arr[j]<=arr[i]).if_else(1,0)
        result[i+1] = (number_of_numbers_lower[len(arr)] == n).if_else(arr[i], result[i])
    return result[len(arr)]

def min_along_axis(arr, axis):
    # Min value for every column
    if axis == 0:
        min_values = [tree_reduce(lambda x, y: x.min(y), list(col)) for col in list(zip(*arr))]
    # Min value for every row
    elif axis == 1:
        min_values = [tree_reduce(lambda x, y: x.min(y), row) for row in arr]
    else:
        raise ValueError("Invalid axis. Use 0 for columns or 1 for rows.")

    return min_values

def extract_columns(X_view, i, j):
    length = len(X_view)
    column_i = Array(length, sfix)
    column_j = Array(length, sfix)

    @for_range_opt(length)
    def _(index):
        column_i[index] = X_view[index][i]
        column_j[index] = X_view[index][j]

    return column_i, column_j

def dot_product_neg_matrix(x, y):
    dp = Array(len(x)+1, sfix)
    dp[0] = sfix(0)
    @for_range_opt(len(x))
    def _(i):
        dp[i] = sfix.dot_product(0 - x[i], y[i])
    return sum(dp[i] for i in range(len(dp)))

def inverse_covariance_matrix(A, iterations=10):
    n = len(A)
    trace_A = sum(A[i][i] for i in range(len(A)))

    c_inv = sint(1) / trace_A
    for _ in range(iterations):
        c_inv *= cint(2) - trace_A * c_inv

    X = Matrix(n, n, sfix)
    two_I = Matrix(n, n, sint)
    two_I_minus_AX = Matrix(n, n, sfix)

    @for_range_opt(n)
    def _(i):
        X[i][i] = c_inv
        two_I[i][i] = cint(2)

    for _ in range(iterations):
        AX = A * X

        @for_range_opt( n)
        def _(i):
            two_I_minus_AX[i] = two_I[i] - AX[i]

        X = X * two_I_minus_AX

    return X



# -------------------------------- EFC --------------------------------

def site_freq(X_view, psdcounts, max_bin):
    n_attr = len(X_view[1])
    sitefreq = Matrix(n_attr, max_bin, sfix)
    X_view_trans = X_view.transpose()
    normalization_factor = (1-psdcounts)/len(X_view)
    baseline_increment = psdcounts / max_bin

    @for_range_opt(n_attr)
    def _(i):
        @for_range_opt(max_bin)
        def _(j):
            sitefreq[i][j] = sum_of_equal_scalar(X_view_trans[i], j)
            sitefreq[i][j] = sitefreq[i][j] * normalization_factor + baseline_increment

    return sitefreq

def pair_freq(X_view, sitefreq_view, psdcounts, max_bin):
    n_inst, n_attr = len(X_view), len(X_view[1])
    pairfreq = MultiArray([n_attr,max_bin,n_attr,max_bin], sfix)

    @for_range_opt(n_attr)
    def _(i):
        @for_range_opt(n_attr)
        def _(j):
            x, y = extract_columns(X_view, i, j)
            arr_len = x.length

            @for_range_opt(arr_len)
            def _(k):
                found_duplicate = sint(0)
                occurence = sint(1)
                cantor_k = cantor(x[k], y[k])

                for l in range(arr_len):
                    cantors_are_equal = (cantor_k - cantor(x[l], y[l])).square()
                    found_duplicate = ((cantors_are_equal + 1 - (l < k)) == 0).if_else(1, found_duplicate)
                    occurence += ((cantors_are_equal + 1 - (l > k)) == 0)

                multiplier = (1-psdcounts)/n_inst

                @for_range_opt(max_bin)
                def _(ai):
                    ai_check = (ai - X_view[k][i]).square()
                    @for_range_opt(max_bin)
                    def _(aj):
                        pairfreq[i][ai][j][aj] = (((found_duplicate) + ai_check + (aj - X_view[k][j]).square()) == 0).if_else(occurence, pairfreq[i][ai][j][aj])

    multiplier = (1-psdcounts)/n_inst
    adder = (psdcounts / (max_bin ** 2))

    # Improvement: in second block of for_range, we dont need to iterate through K:
    # In the if_else statements we had before, we would only change value if i == k
    @for_range_opt(n_attr)
    def _(i):
        @for_range_opt(max_bin)
        def _(j):
            @for_range_opt(n_attr)
            def _(k):
                @for_range_opt(max_bin)
                def _(l):
                    pairfreq[i][j][k][l] = pairfreq[i][j][k][l] * multiplier + adder
    @for_range_opt(n_attr)
    def _(i):
        @for_range_opt(max_bin)
        def _(j):
            @for_range_opt(max_bin)
            def _(l):
                pairfreq[i][j][i][l] = (j == l).if_else(sitefreq_view[i][j], 0)

    return pairfreq

def coupling(pairfreq_view, sitefreq_view, max_bin):
    n_attr = len(sitefreq_view)
    corr_matrix = Matrix(n_attr * (max_bin - 1),  n_attr * (max_bin - 1), sfix)

    @for_range_opt(n_attr)
    def _(i):
        @for_range_opt(n_attr)
        def _(j):
            @for_range_opt(max_bin-1)
            def _(ai):
                @for_range_opt(max_bin-1)
                def _(aj):
                    corr_matrix[i * (max_bin - 1) + ai][j * (max_bin - 1) + aj] = pairfreq_view[i][ai][j][aj] - sitefreq_view[i][ai] * sitefreq_view[j][aj]
    return inverse_covariance_matrix(corr_matrix)

def local_fields(coupling_view, pairfreq_view, sitefreq_view, psdcounts, max_bin):
    n_inst = len(sitefreq_view)
    fields = Array(n_inst * (max_bin - 1), sfix)
    @for_range_opt(n_inst)
    def _(i):
        @for_range_opt(max_bin - 1)
        def _(ai):
            idx = i * (max_bin - 1) + ai
            fields[idx] = sitefreq_view[i][ai] / sitefreq_view[i][max_bin - 1]
            acc = Array((n_inst*(max_bin - 1))+1, sfix)
            acc[0] = 0
            @for_range_opt(n_inst)
            def _(j):
                @for_range_opt(max_bin - 1)
                def _(aj):
                    acc[1+ (j*(max_bin-1)) + aj] = acc[(j*(max_bin-1)) + aj] + (-coupling_view[idx][j * (max_bin - 1) + aj] * sitefreq_view[j][aj])
            fields[idx] = mpc_math.log_fx(fields[idx], E) - acc[n_inst*(max_bin - 1)]
    return fields


def compute_energy(X, coupling_matrix, local_fields, max_bin):
    n_inst, n_attr = len(X), len(X[0])
    energies = Array(n_inst, sfix)

    print_ln("coupling_matrix energy: %s", coupling_matrix.reveal())
    print_ln("local_fields energy: %s", local_fields.reveal())

    coupling_matrix_len = len(coupling_matrix)
    local_field_len = len(local_fields)

    @for_range_opt(n_inst)
    def _(i):
        selector_fields = local_fields.same_shape().assign_all(0.0)
        selector_coupling = coupling_matrix.same_shape().assign_all(0.0)

        @for_range_opt(n_attr)
        def _(j):
            j_value = X[i][j]
            is_j_value = (j_value != (max_bin-1))
            value_condition_1 = j * (max_bin - 1) + j_value

            @for_range_opt(j, n_attr)
            def _(k):
                k_value = (1 - is_j_value).if_else(max_bin-1, X[i][k])
                is_k_value = k_value != (max_bin-1)
                value_condition_2 = k * (max_bin - 1) + k_value

                @for_range_opt(coupling_matrix_len)
                def _(l):
                    @for_range_opt(coupling_matrix_len)
                    def _(m):
                        selector_coupling[l][m] = (((l-value_condition_1).square() + (m-value_condition_2).square() + (1-is_k_value).square()) == 0).if_else(1,selector_coupling[l][m])

            @for_range_opt(local_field_len)
            def _(k):
                condition1 = ((k == (j * (max_bin - 1) + j_value))).if_else(1,0)
                selector_fields[k] = (condition1 + is_j_value==2).if_else(1, selector_fields[k])

        energies[i] -= (dot_product_neg_matrix(coupling_matrix, selector_coupling) + sfix.dot_product(local_fields, selector_fields))

    print_ln("Energies: %s", energies.reveal())

    return energies


def fit(X, pseudocounts, max_bin):
    sitefreq = site_freq(X, pseudocounts, max_bin)
    pairfreq = pair_freq(X,sitefreq, pseudocounts, max_bin)
    coupling_matrix = coupling(pairfreq, sitefreq, max_bin)
    localfields = local_fields(coupling_matrix, pairfreq, sitefreq, pseudocounts, max_bin)
    cutoff = define_cutoff(X, 0.95, coupling_matrix, localfields, max_bin)

    return coupling_matrix, localfields, cutoff

def define_cutoff(X, cutoff_quantile, coupling_matrix, local_fields, max_bin):
    energies = compute_energy(X, coupling_matrix, local_fields, max_bin)
    return find_nth_largest_value_from_array(energies, int(len(energies) * cutoff_quantile))

def predict(X, coupling_matrix, localfields, cutoff, max_bin):
    energies = [compute_energy(X, coupling_matrix, localfields, max_bin)]
    n_inst = len(X)
    y_pred = Array(n_inst, cint)

    min_energies = min_along_axis(energies, 0)

    for row in range(n_inst):
        y_pred[row] = (min_energies[row] >= cutoff).reveal()

    return y_pred
# -------------------------------- TEST --------------------------------


def data_preprocessing():

    X_train = pd.read_csv("Programs/Source/EFC-MP-SPDZ/thesis/no_rabbit/data/train.csv")
    X_test = pd.read_csv("Programs/Source/EFC-MP-SPDZ/thesis/no_rabbit/data/test.csv")

    y_train = X_train["target"].values.tolist()
    y_test = X_test["target"].values.tolist()

    X_train = X_train.drop(columns=["target"]).values.tolist()
    X_test = X_test.drop(columns=["target"]).values.tolist()

    max_bin = max(max(max(row) for row in X_train), max(max(row) for row in X_test)) + 1

    n_attr = len(X_train[0])
    local_fields_shape = n_attr * (max_bin - 1)
    coupling_matrix_shape = n_attr * (max_bin - 1)
    return X_train, X_test, y_train, y_test, local_fields_shape, coupling_matrix_shape, max_bin

def test_training_phase(X_train, X_test, y_train, y_test, max_bin, local_fields_shape, coupling_matrix_shape):
    X_train = sint.input_tensor_via(0, X_train)

    coupling_matrix, localfields, cutoff = fit(X_train, 0.5, max_bin)

    # Save the classifier info to file
    cutoff_arr = Array(1, sfix)
    cutoff_arr[0] = cutoff
    cutoff_arr.write_to_file(position = 0)
    coupling_matrix.write_to_file(position = 1)

    localfields.write_to_file(position = (1+(coupling_matrix_shape * coupling_matrix_shape)))

    print_ln("%s cutoff orig", cutoff.reveal())
    print_ln("%s couplong", coupling_matrix.reveal())
    print_ln("%s localfields", localfields.reveal())


def test_inference_phase(X_train, X_test, y_train, y_test, max_bin, local_fields_shape, coupling_matrix_shape):
    X_test = sint.input_tensor_via(0, X_test)
    y_test = sint.input_tensor_via(0, y_test)


    coupling_matrix = Matrix(coupling_matrix_shape, coupling_matrix_shape, sfix)
    localfields = Array(local_fields_shape, sfix)

    cutoff_arr_presaved = Array(1, sfix)
    cutoff_arr_presaved.read_from_file(0)
    cutoff_presaved = cutoff_arr_presaved[0]
    coupling_matrix_presaved = Matrix(len(coupling_matrix), len(coupling_matrix[0]), sfix)
    coupling_matrix_presaved.read_from_file(1)
    localfields_presaved = Array(len(localfields), sfix)
    localfields_presaved.read_from_file(1+(len(coupling_matrix)*len(coupling_matrix[0])))

    print_ln("%s cutoff presaved", cutoff_presaved.reveal())
    print_ln("%s couplong presaved", coupling_matrix_presaved.reveal())
    print_ln("%s localfields presaved", localfields_presaved.reveal())

    y_pred_presaved = predict(X_test, coupling_matrix_presaved, localfields_presaved, cutoff_presaved, max_bin)
    y_pred_presaved.print_reveal_nested()
    precision, recall = calculate_metrics(y_test, y_pred_presaved)

#----------------------------------- MAIN -----------------------------------

X_train, X_test, y_train, y_test, local_fields_shape, coupling_matrix_shape, max_bin = data_preprocessing()

start_timer(1)
test_training_phase(X_train, X_test, y_train, y_test, max_bin, local_fields_shape, coupling_matrix_shape)
stop_timer(1)
start_timer(2)
test_inference_phase(X_train, X_test, y_train, y_test, max_bin, local_fields_shape, coupling_matrix_shape)
stop_timer(2)
